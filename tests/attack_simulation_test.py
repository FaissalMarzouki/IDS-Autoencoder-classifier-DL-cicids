import numpy as np
import torch
import json
import os
import sys

# Configuration du chemin pour importer les modules locaux
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from processors.preprocessor import DataPreprocessor
from processors.detector import IDSDetector

class FullFlowTest:
    def __init__(self):
        print("ðŸ› ï¸  Initialisation du pipeline de test...")
        # Initialisation avec des topics fictifs
        self.preprocessor = DataPreprocessor(input_topic="raw_test", output_topic="feat_test")
        self.detector = IDSDetector(input_topic="feat_test", output_topic="alerts_test")
        
        # Intercepteur pour le passage entre Preprocessor et Detector
        self.preprocessed_output = None
        self.preprocessor.send_message = self._capture_output

    def _capture_output(self, data):
        self.preprocessed_output = data

    def generate_raw_traffic(self, scenario="normal"):
        """GÃ©nÃ¨re les donnÃ©es d'entrÃ©e brutes"""
        # On utilise les noms de colonnes exacts attendus par votre scaler
        expected = self.preprocessor.feature_names
        data = {"flow_id": f"flow_{scenario}_{np.random.randint(100)}"}
        
        # Valeurs par dÃ©faut
        for f in expected: data[f] = 0.0

        if scenario == "ddos":
            # On force des valeurs qui s'Ã©cartent du trafic normal
            data[" Destination Port"] = 80
            data[" Total Fwd Packets"] = 15000.0
            data[" Flow Duration"] = 10.0
            data[" Flow Bytes/s"] = 5000000.0
        elif scenario == "portscan":
            data[" Destination Port"] = 22
            data[" Flow Duration"] = 1.0
            data[" SYN Flag Count"] = 1.0
        else: # normal
            data[" Destination Port"] = 443
            data[" Total Fwd Packets"] = 10.0
            data[" Flow Duration"] = 50000.0

        return data

    def run(self):
        scenarios = ["normal", "ddos", "portscan"]
        
        print(f"\n{'='*80}")
        print(f"ðŸš€ DÃ‰MARRAGE DU TEST DE FLUX COMPLET (DEBUG MODE)")
        print(f"{'='*80}")

        for sc in scenarios:
            print(f"\n\n>>> ðŸŸ¢ SCÃ‰NARIO : {sc.upper()}")
            
            # --- Ã‰TAPE 1 : GÃ‰NÃ‰RATION ---
            print(f"\n[Ã‰tape 1] GÃ©nÃ©ration des donnÃ©es brutes")
            raw_data = self.generate_raw_traffic(sc)
            # On n'affiche que les colonnes modifiÃ©es pour la lisibilitÃ©
            relevant_input = {k: v for k, v in raw_data.items() if v != 0 and k != "flow_id"}
            print(f"  ðŸ“¥ INPUT  (Raw): {json.dumps(relevant_input, indent=2)}")

            # --- Ã‰TAPE 2 : PREPROCESSING ---
            print(f"\n[Ã‰tape 2] Preprocessing (Clipping & Scaling)")
            self.preprocessor.process(raw_data)
            
            if self.preprocessed_output:
                # Affichage des 5 premiÃ¨res features scalÃ©es pour vÃ©rification
                sample_features = self.preprocessed_output['features'][:5]
                print(f"  ðŸ“¥ INPUT  (au Preprocessor): {len(raw_data)} colonnes")
                print(f"  ðŸ“¤ OUTPUT (Scaled): {sample_features}... (Total: {len(self.preprocessed_output['features'])} features)")
            
                # --- Ã‰TAPE 3 : DETECTION ---
                print(f"\n[Ã‰tape 3] Analyse par l'Autoencoder + Classifier")
                self.detector.process(self.preprocessed_output)
            
            # Reset
            self.preprocessed_output = None

# On modifie temporairement le process du Detector pour voir les probabilitÃ©s
def verbose_detector_process(self, data):
    # 1. Scaling final (clipping interne au detector)
    feat_array = np.array(data['features']).reshape(1, -1)
    feat_clipped = np.clip(feat_array, self.percentiles['p01'], self.percentiles['p99'])
    # On Ã©vite le warning en passant .values ou un array sans noms de colonnes
    feat_scaled = self.scaler.transform(feat_clipped)
    
    # 2. InfÃ©rence
    features_tensor = torch.tensor(feat_scaled, dtype=torch.float32)
    with torch.no_grad():
        logits = self.model(features_tensor)
        probs = torch.softmax(logits, dim=1)
        conf, pred_idx = torch.max(probs, dim=1)
    
    prediction = self.label_encoder.inverse_transform([pred_idx.item()])[0]
    
    # Affichage du rÃ©sultat interne
    print(f"  ðŸ“¥ INPUT  (Tensor): {features_tensor.shape}")
    print(f"  ðŸ“¤ OUTPUT (Pred): {prediction}")
    print(f"  ðŸ“Š CONFIDENCE: {conf.item():.2%}")
    
    if prediction != "Normal Traffic":
        print(f"  ðŸš¨ ALERT GENERATED: {prediction}")

# Injection de la mÃ©thode verbeuse
IDSDetector.process = verbose_detector_process

if __name__ == "__main__":
    tester = FullFlowTest()
    tester.run()
