"""
Test de validation de la qualit√© du mod√®le
V√©rifie que le mod√®le peut distinguer les classes
"""
import numpy as np
import torch
import joblib
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import ARTIFACTS_PATH
from processors.detector import IDSDetector

def test_model_quality():
    """Teste si le mod√®le peut distinguer les classes"""
    print("="*80)
    print("üî¨ TEST DE QUALIT√â DU MOD√àLE")
    print("="*80)
    
    detector = IDSDetector(input_topic="test", output_topic="test")
    
    # Charger les classes
    classes = detector.label_encoder.classes_
    print(f"\nüìä Classes du mod√®le ({len(classes)}):")
    for i, cls in enumerate(classes):
        print(f"   {i}: {cls}")
    
    # Test: cr√©er des donn√©es al√©atoires et voir la distribution
    print(f"\n" + "="*80)
    print("TEST 1: Distribution avec donn√©es al√©atoires")
    print("="*80)
    
    # Cr√©er 100 samples al√©atoires
    predictions = {cls: 0 for cls in classes}
    
    for i in range(100):
        # Donn√©es al√©atoires normalis√©es (mean=0, std=1)
        random_features = np.random.randn(1, 37)
        
        with torch.no_grad():
            tensor = torch.tensor(random_features, dtype=torch.float32)
            logits = detector.model(tensor)
            probs = torch.softmax(logits, dim=1)
            conf, pred_idx = torch.max(probs, dim=1)
        
        pred_class = detector.label_encoder.inverse_transform([pred_idx.item()])[0]
        predictions[pred_class] += 1
    
    print(f"\nüìà Pr√©dictions sur 100 samples al√©atoires:")
    for cls in classes:
        print(f"   {cls:20s}: {predictions[cls]:3d} ({predictions[cls]/100*100:5.1f}%)")
    
    # Test 2: V√©rifier que le mod√®le n'est pas gel√©
    print(f"\n" + "="*80)
    print("TEST 2: V√©rification des poids du mod√®le")
    print("="*80)
    
    total_params = sum(p.numel() for p in detector.model.parameters())
    trainable_params = sum(p.numel() for p in detector.model.parameters() if p.requires_grad)
    
    print(f"\nüì¶ Nombre de param√®tres:")
    print(f"   Total: {total_params:,}")
    print(f"   Entra√Ænables: {trainable_params:,}")
    
    # Afficher les min/max de quelques poids
    for name, param in list(detector.model.named_parameters())[:3]:
        print(f"\n   {name}:")
        print(f"     Min: {param.data.min():.6f}, Max: {param.data.max():.6f}")
    
    # Test 3: V√©rifier la capacit√© discriminante du classifier
    print(f"\n" + "="*80)
    print("TEST 3: √ânergie du classifier (poids finaux)")
    print("="*80)
    
    # Afficher les poids du dernier layer (classification)
    classifier = detector.model.classifier
    last_layer = list(classifier.modules())[-1]
    
    if hasattr(last_layer, 'weight'):
        weights = last_layer.weight.data
        print(f"\nPoids du classifier ({weights.shape}):")
        print(f"   Min: {weights.min():.4f}, Max: {weights.max():.4f}")
        
        # V√©rifier qu'il y a de la variation entre classes
        weight_variance = weights.var(dim=0).mean()
        print(f"   Variance moyenne par neurone: {weight_variance:.6f}")
        
        if weight_variance < 0.001:
            print(f"   ALERTE: Variance tr√®s faible - le mod√®le peut √™tre d√©g√©n√©r√©!")

if __name__ == "__main__":
    test_model_quality()
