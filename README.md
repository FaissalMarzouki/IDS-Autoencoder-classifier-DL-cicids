# ğŸ›¡ï¸ IDS-Autoencoder-Classifier-DL-CICIDS

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ Description

SystÃ¨me de DÃ©tection d'Intrusions (IDS) basÃ© sur le **Deep Learning** utilisant une architecture hybride **Autoencoder + Classifier** pour la dÃ©tection en temps rÃ©el d'attaques rÃ©seau.

Ce projet implÃ©mente une approche combinant:
- **DÃ©tection supervisÃ©e** : Classification des attaques connues
- **DÃ©tection d'anomalies** : Identification des comportements inhabituels via l'erreur de reconstruction

## ğŸ—ï¸ Architecture du ModÃ¨le

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUTOENCODER IDS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  INPUT (52 features) â”€â”€â–º ENCODER â”€â”€â–º LATENT (16 dims)          â”‚
â”‚                              â”‚              â”‚                   â”‚
â”‚                              â”‚              â”œâ”€â”€â–º DECODER â”€â”€â–º RECONSTRUCTION
â”‚                              â”‚              â”‚                   â”‚
â”‚                              â”‚              â””â”€â”€â–º CLASSIFIER â”€â”€â–º 7 CLASSES
â”‚                              â”‚                                  â”‚
â”‚                              â””â”€â”€â–º Reconstruction Error â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Dataset

**CICIDS2017** - Canadian Institute for Cybersecurity Intrusion Detection Dataset
- **2,520,751** flux rÃ©seau
- **52** features extraites
- **7** classes (Normal + 6 types d'attaques)

### Classes de Trafic:
| Classe | Description |
|--------|-------------|
| Normal | Trafic lÃ©gitime |
| DDoS | Distributed Denial of Service |
| DoS | Denial of Service |
| Bots | Machines infectÃ©es (botnets) |
| PortScan | Reconnaissance par scan de ports |
| WebAttack | Attaques web (SQL Injection, XSS, Brute Force) |
| Infiltration | Intrusion dans le rÃ©seau |

## ğŸš€ Installation

```bash
# Cloner le repository
git clone https://github.com/FaissalMarzouki/IDS-Autoencoder-classifier-DL-cicids.git
cd IDS-Autoencoder-classifier-DL-cicids

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸ“¦ DÃ©pendances

```
torch>=2.0.0
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
imbalanced-learn>=0.11.0
joblib>=1.3.0
tqdm>=4.65.0
```

## ğŸ“ Structure du Projet

```
IDS-Autoencoder-classifier-DL-cicids/
â”‚
â”œâ”€â”€ IDS_DL_NOTEBOOK_COMPLETE.ipynb    # Notebook principal (entraÃ®nement complet)
â”œâ”€â”€ CICIDS2017_Quick_Analysis.ipynb   # Analyse exploratoire rapide
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ cicids2017_cleaned.csv        # Dataset nettoyÃ©
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ autoencoder_ids_v1.1.0.pt     # ModÃ¨le PyTorch entraÃ®nÃ©
â”‚   â”œâ”€â”€ model_config.json             # Configuration du modÃ¨le
â”‚   â”œâ”€â”€ scaler.joblib                 # Scaler pour normalisation
â”‚   â”œâ”€â”€ label_encoder.joblib          # Encodeur des labels
â”‚   â”œâ”€â”€ feature_names.json            # Noms des features
â”‚   â””â”€â”€ percentiles.joblib            # Percentiles pour clipping
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_curves.png           # Courbes d'entraÃ®nement
â”‚   â”œâ”€â”€ confusion_matrix.png          # Matrice de confusion
â”‚   â”œâ”€â”€ latent_space_tsne.png         # Visualisation t-SNE
â”‚   â””â”€â”€ reconstruction_error_analysis.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```

## ğŸ¯ RÃ©sultats

| MÃ©trique | Score |
|----------|-------|
| **Accuracy** | ~95% |
| **F1-Score (Weighted)** | ~94% |
| **F1-Score (Macro)** | ~90% |
| **ROC-AUC** | ~98% |

### Visualisations

<p align="center">
  <img src="results/confusion_matrix.png" width="45%" />
  <img src="results/latent_space_tsne.png" width="45%" />
</p>

## ğŸ’» Utilisation

### EntraÃ®nement
ExÃ©cuter le notebook `IDS_DL_NOTEBOOK_COMPLETE.ipynb` cellule par cellule.

### InfÃ©rence (PrÃ©diction)
```python
import torch
import json
import joblib

# Charger le modÃ¨le
model = AutoencoderIDS(config)
model.load_state_dict(torch.load('models/autoencoder_ids_v1.1.0.pt'))
model.eval()

# Charger les prÃ©processeurs
scaler = joblib.load('models/scaler.joblib')
label_encoder = joblib.load('models/label_encoder.joblib')

# PrÃ©dire
with torch.no_grad():
    features_scaled = scaler.transform(features)
    prediction = model.predict(torch.tensor(features_scaled, dtype=torch.float32))
```

### Format de Sortie JSON (pour intÃ©gration LLM)
```json
{
  "flow_id": "flow_001",
  "timestamp": "2024-01-15T10:30:00Z",
  "prediction": {
    "class": "DDoS",
    "confidence": 0.95,
    "anomaly_score": 0.82
  },
  "features_summary": {
    "bytes_sent": 150000,
    "packets": 1200,
    "duration": 2.5
  }
}
```

## ğŸ”¬ Techniques UtilisÃ©es

- **Focal Loss** : Gestion du dÃ©sÃ©quilibre des classes (ratio 1075:1)
- **Batch Normalization** : Stabilisation de l'entraÃ®nement
- **Dropout** : RÃ©gularisation (0.3)
- **Early Stopping** : PrÃ©vention du surapprentissage
- **Under-sampling stratifiÃ©** : Ã‰quilibrage du dataset
- **StandardScaler avec clipping** : Normalisation robuste aux outliers

## ğŸ“š RÃ©fÃ©rences

- [CICIDS2017 Dataset](https://www.unb.ca/cic/datasets/ids-2017.html)
- [Autoencoder for Anomaly Detection](https://arxiv.org/abs/1906.02994)
- [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)

## ğŸ‘¤ Auteur

**Faissal Marzouki**

## ğŸ“„ License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

â­ N'hÃ©sitez pas Ã  mettre une Ã©toile si ce projet vous a Ã©tÃ© utile!
