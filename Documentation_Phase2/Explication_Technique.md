# Explication Technique du Pipeline IDS Kafka

## Table des Mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Comment fonctionne chaque composant](#comment-fonctionne-chaque-composant)
3. [Patterns Kafka utilis√©s](#patterns-kafka-utilis√©s)
4. [Threading et Concurrence](#threading-et-concurrence)
5. [Gestion des Donn√©es](#gestion-des-donn√©es)
6. [Points Importants](#points-importants)

---

## Vue d'ensemble

Le fichier `automated_ids_pipeline.py` impl√©mente un **pipeline de d√©tection d'intrusions en temps r√©el** utilisant :
- **Apache Kafka** pour le streaming de donn√©es
- **AutoencoderIDS** (PyTorch) pour la d√©tection
- **Threading Python** pour le traitement parall√®le

### Flux Simplifi√©

```
CSV ‚Üí Producer ‚Üí Topic1 ‚Üí Consumer/Producer ‚Üí Topic2 ‚Üí Detector ‚Üí Topic3 ‚Üí Monitor
```

---

## Comment fonctionne chaque composant

### 1. **TrafficProducer** - Le G√©n√©rateur de Trafic

```python
class TrafficProducer:
    def __init__(self, dataset_path, bootstrap_servers):
        # 1. Charge le simulateur (lit le CSV)
        self.simulator = TrafficSimulator(dataset_path)
        
        # 2. Cr√©e un producer Kafka
        self.producer = KafkaProducer(
            bootstrap_servers=bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
```

**Ce qu'il fait** :
1. Lit le dataset CICIDS2017 (500 flux r√©seau dans votre cas)
2. S√©lectionne al√©atoirement des flux selon le ratio d'attaque
3. Envoie chaque flux vers le topic `ids-raw-data`
4. Attend `delay` secondes entre chaque envoi

**Exemple concret** :
```python
# G√©n√®re 200 flux avec 20% d'attaques
for i, flow in enumerate(simulator.generate_stream(200, 0.2)):
    # flow = {flow_id, features[37], label, timestamp}
    producer.send('ids-raw-data', flow.to_dict())
    time.sleep(0.05)  # D√©lai 50ms
```

**Pourquoi c'est important** :
- Simule un flux r√©seau r√©el
- Permet de tester le syst√®me avec diff√©rents ratios d'attaque
- Le d√©lai √©vite de surcharger Kafka

---

### 2. **DataPreprocessor** - Le Validateur

```python
class DataPreprocessor:
    def __init__(self, bootstrap_servers):
        # Consumer : lit depuis ids-raw-data
        self.consumer = KafkaConsumer('ids-raw-data', ...)
        
        # Producer : √©crit vers ids-features
        self.producer = KafkaProducer(...)
```

**Ce qu'il fait** :
1. **Consomme** les messages de `ids-raw-data`
2. **Valide** la structure des donn√©es
3. **Ajoute** des m√©tadonn√©es (timestamp de preprocessing)
4. **Produit** vers `ids-features`

**Code cl√©** :
```python
def process_flow(self, raw_data: dict) -> dict:
    return {
        'flow_id': raw_data['flow_id'],
        'features': raw_data['features'],  # 37 valeurs num√©riques
        'label': raw_data['label'],        # ex: "DDoS"
        'timestamp': raw_data['timestamp'],
        'preprocessed_at': datetime.now().isoformat()  # NOUVEAU
    }

def run(self):
    for message in self.consumer:
        # 1. Lire le message
        raw_data = message.value
        
        # 2. Traiter
        features_data = self.process_flow(raw_data)
        
        # 3. Envoyer
        self.producer.send('ids-features', features_data)
        
        print(f"[OK] {raw_data['flow_id']} ‚Üí ids-features")
```

**Pourquoi c'est important** :
- S√©pare la g√©n√©ration de donn√©es du traitement
- Permet d'ajouter facilement des validations
- Trace quand chaque flux a √©t√© trait√©

---

### 3. **ThreatDetector** - Le Cerveau du Syst√®me

```python
class ThreatDetector:
    def __init__(self, models_dir, bootstrap_servers):
        # 1. Charge le mod√®le PyTorch
        self.predictor = IDSPredictor(models_dir)
        
        # 2. Consumer depuis ids-features
        self.consumer = KafkaConsumer('ids-features', ...)
        
        # 3. Producer vers ids-alerts
        self.producer = KafkaProducer(...)
```

**Ce qu'il fait** :
1. **Consomme** depuis `ids-features`
2. **Charge** les features dans le mod√®le AutoencoderIDS
3. **Pr√©dit** la classe d'attaque + confiance + anomaly score
4. **Calcule** la s√©v√©rit√© (CRITIQUE/√âLEV√âE/MOYENNE/FAIBLE)
5. **Publie** vers `ids-alerts` **SEULEMENT SI ATTAQUE**

**Code cl√©** :
```python
def detect(self, features_data: dict):
    # 1. Pr√©diction avec le mod√®le
    prediction = self.predictor.predict(
        features_data['features'],
        features_data['flow_id']
    )
    # prediction = {
    #     predicted_class: "DDoS",
    #     confidence: 0.9534,
    #     anomaly_score: 0.002341,
    #     is_attack: True,
    #     all_probabilities: {...}
    # }
    
    # 2. UNIQUEMENT SI ATTAQUE
    if prediction.is_attack:
        # Cr√©er l'alerte
        alert = {
            'timestamp': datetime.now().isoformat(),
            'flow_id': features_data['flow_id'],
            'alert_type': prediction.predicted_class,
            'confidence': prediction.confidence,
            'anomaly_score': prediction.anomaly_score,
            'severity': self._calculate_severity(prediction),
            'true_label': features_data['label'],
            'correct': prediction.predicted_class == features_data['label'],
            'all_probabilities': prediction.all_probabilities,
            'top_3_classes': [...]
        }
        
        # Envoyer vers Kafka
        self.producer.send('ids-alerts', alert)
        print(f"[ALERTE] {prediction.predicted_class} ({prediction.confidence:.1%})")
    else:
        # Trafic normal - pas d'alerte
        print(f"[OK] Trafic normal (conf: {prediction.confidence:.1%})")
```

**Calcul de la s√©v√©rit√©** :
```python
def _calculate_severity(self, prediction) -> str:
    if prediction.confidence >= 0.9:
        return "CRITIQUE"    # Rouge
    elif prediction.confidence >= 0.7:
        return "√âLEV√âE"      # Jaune
    elif prediction.confidence >= 0.5:
        return "MOYENNE"     # Bleu
    else:
        return "FAIBLE"      # Vert
```

**‚ö†Ô∏è CHANGEMENT IMPORTANT** :
- **Avant** : Envoyait toujours vers `ids-explanations`
- **Maintenant** : Envoie vers `ids-alerts` uniquement si attaque
- **Phase 2** : Le `LLMExplainer` consommera `ids-alerts` et produira `ids-explanations`

**Pourquoi c'est important** :
- R√©duit le volume de donn√©es (pas d'alertes pour le trafic normal)
- Permet au LLM de traiter uniquement les vrais incidents
- √âconomise des ressources (appels API LLM co√ªteux)

---

### 4. **AlertMonitor** - L'Afficheur

```python
class AlertMonitor:
    def __init__(self, bootstrap_servers):
        # Consumer depuis ids-alerts
        self.consumer = KafkaConsumer('ids-alerts', ...)
        
        # Statistiques
        self.total_alerts = 0
        self.alerts_by_type = {}
        self.start_time = time.time()
```

**Ce qu'il fait** :
1. **Consomme** depuis `ids-alerts`
2. **Affiche** chaque alerte avec code couleur
3. **Calcule** des statistiques en temps r√©el
4. **Affiche** un rapport final √† l'arr√™t

**Code cl√©** :
```python
def display_alert(self, alert: dict):
    severity = alert['severity']
    
    # Codes couleur ANSI
    colors = {
        'CRITIQUE': '\033[91m',  # Rouge
        '√âLEV√âE': '\033[93m',     # Jaune
        'MOYENNE': '\033[94m',    # Bleu
        'FAIBLE': '\033[92m'      # Vert
    }
    color = colors[severity]
    reset = '\033[0m'
    
    # Affichage format√©
    print("\n" + "="*70)
    print(f"{color}üö® ALERTE S√âCURIT√â - S√©v√©rit√©: {severity}{reset}")
    print("="*70)
    print(f"  Horodatage:     {alert['timestamp']}")
    print(f"  Flow ID:        {alert['flow_id']}")
    print(f"  Type d'attaque: {alert['alert_type']}")
    print(f"  Confiance:      {alert['confidence']:.1%}")
    print(f"  Score anomalie: {alert['anomaly_score']:.6f}")
    print("="*70)
    
    # Statistiques
    self.total_alerts += 1
    self.alerts_by_type[alert['alert_type']] = \
        self.alerts_by_type.get(alert['alert_type'], 0) + 1

def print_stats(self):
    elapsed = time.time() - self.start_time
    print("\nüìä STATISTIQUES DE SURVEILLANCE")
    print(f"  Dur√©e:          {elapsed:.1f}s")
    print(f"  Total alertes:  {self.total_alerts}")
    print(f"  Taux:           {self.total_alerts / elapsed:.2f} alertes/s")
    print("\n  R√©partition par type:")
    for attack_type, count in sorted(self.alerts_by_type.items()):
        pct = count / self.total_alerts * 100
        print(f"    - {attack_type:20}: {count:4} ({pct:.1f}%)")
```

**Pourquoi c'est important** :
- Feedback visuel imm√©diat
- Permet de voir le syst√®me fonctionner en temps r√©el
- Statistiques utiles pour l'√©valuation

---

## Patterns Kafka utilis√©s

### 1. **Producer-Consumer Pattern**

Chaque composant impl√©mente ce pattern :

```python
# Consumer (lit depuis un topic)
consumer = KafkaConsumer(
    'input-topic',
    bootstrap_servers='localhost:9093',
    group_id='unique-group-id',           # Important !
    value_deserializer=lambda m: json.loads(m.decode('utf-8')),
    auto_offset_reset='latest'            # Lit nouveaux messages uniquement
)

# Producer (√©crit vers un topic)
producer = KafkaProducer(
    bootstrap_servers='localhost:9093',
    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
    request_timeout_ms=30000,
    max_block_ms=30000
)

# Boucle de traitement
for message in consumer:
    # 1. Lire
    data = message.value
    
    # 2. Traiter
    result = process(data)
    
    # 3. √âcrire
    producer.send('output-topic', result)
```

**Concepts cl√©s** :
- **Consumer Group** : Permet le load balancing (plusieurs consumers lisent le m√™me topic)
- **Deserializer** : Convertit bytes ‚Üí dict Python
- **Serializer** : Convertit dict Python ‚Üí bytes
- **auto_offset_reset** : `latest` = nouveaux messages, `earliest` = tous les messages

### 2. **Fan-out Pattern**

Un producer envoie vers plusieurs topics :

```python
# ThreatDetector envoie vers ids-alerts
producer.send('ids-alerts', alert)

# (Phase 2) LLMExplainer envoie vers ids-explanations
producer.send('ids-explanations', explanation)
```

### 3. **At-Least-Once Delivery**

Kafka garantit que chaque message est trait√© au moins une fois :

```python
# Consumer commit automatiquement apr√®s traitement
# Si crash avant commit ‚Üí message retrait√©
for message in consumer:
    process(message.value)  # Si crash ici, message retrait√©
```

---

## Threading et Concurrence

### Architecture Multi-Thread

```python
def run_pipeline(...):
    threads = []
    
    # Thread 1: DataPreprocessor
    preprocessor = DataPreprocessor(kafka_server)
    t1 = threading.Thread(target=preprocessor.run, daemon=True)
    t1.start()
    threads.append(t1)
    
    # Thread 2: ThreatDetector
    detector = ThreatDetector(bootstrap_servers=kafka_server)
    t2 = threading.Thread(target=detector.run, daemon=True)
    t2.start()
    threads.append(t2)
    
    # Thread 3: AlertMonitor
    monitor = AlertMonitor(kafka_server)
    t3 = threading.Thread(target=monitor.run, daemon=True)
    t3.start()
    threads.append(t3)
    
    # Thread principal: TrafficProducer
    producer = TrafficProducer(dataset_path, kafka_server)
    producer.run(count, attack_ratio, delay)
```

**Concepts cl√©s** :

1. **Daemon Thread** :
   ```python
   threading.Thread(..., daemon=True)
   ```
   - Se termine automatiquement quand le programme principal s'arr√™te
   - Pas besoin de `join()`
   - Id√©al pour les services en arri√®re-plan

2. **Pourquoi plusieurs threads** :
   - Chaque consumer Kafka fait du **polling** (boucle infinie)
   - Sans threads, le premier consumer bloquerait les suivants
   - Les threads permettent le traitement **parall√®le**

3. **Ordre d'ex√©cution** :
   ```
   t=0s    D√©marrer DataPreprocessor     (thread 1)
   t=1s    D√©marrer ThreatDetector       (thread 2)
   t=2s    D√©marrer AlertMonitor         (thread 3)
   t=3s    D√©marrer TrafficProducer      (thread principal)
   ```
   - Les consumers d√©marrent d'abord (attendent les donn√©es)
   - Le producer d√©marre en dernier (g√©n√®re les donn√©es)

4. **Gestion de l'arr√™t** :
   ```python
   try:
       for message in consumer:
           process(message)
   except KeyboardInterrupt:
       print("Arr√™t demand√©")
   finally:
       consumer.close()
       producer.close()
   ```
   - `Ctrl+C` d√©clenche `KeyboardInterrupt`
   - `finally` garantit la fermeture propre

---

## Gestion des Donn√©es

### Format des Messages Kafka

Tous les messages sont en **JSON** :

```python
# Topic: ids-raw-data
{
  "flow_id": "sim_00000042",
  "features": [
    80.0,      # Port destination
    0.0,       # Flag FIN
    2.0,       # Nombre de paquets
    128.0,     # Taille moyenne des paquets
    # ... 33 autres features
  ],
  "label": "DDoS",
  "timestamp": 1703672400.0
}

# Topic: ids-features (apr√®s preprocessing)
{
  "flow_id": "sim_00000042",
  "features": [...],
  "label": "DDoS",
  "timestamp": 1703672400.0,
  "preprocessed_at": "2024-12-28T10:45:23.456789"  # AJOUT√â
}

# Topic: ids-alerts (si attaque)
{
  "timestamp": "2024-12-28T10:45:23.456789",
  "flow_id": "sim_00000042",
  "alert_type": "DDoS",
  "confidence": 0.9534,
  "anomaly_score": 0.002341,
  "severity": "CRITIQUE",
  "true_label": "DDoS",
  "correct": true,
  "all_probabilities": {
    "Bots": 0.0012,
    "Brute Force": 0.0023,
    "DDoS": 0.9534,
    "DoS": 0.0312,
    "Normal Traffic": 0.0089,
    "Port Scanning": 0.0015,
    "Web Attacks": 0.0015
  },
  "top_3_classes": [
    ["DDoS", 0.9534],
    ["DoS", 0.0312],
    ["Normal Traffic", 0.0089]
  ]
}
```

### S√©rialisation/D√©s√©rialisation

```python
# S√©rialisation (Producer)
value_serializer=lambda v: json.dumps(v).encode('utf-8')
# dict ‚Üí JSON string ‚Üí bytes

# D√©s√©rialisation (Consumer)
value_deserializer=lambda m: json.loads(m.decode('utf-8'))
# bytes ‚Üí JSON string ‚Üí dict
```

**Pourquoi JSON** :
- Lisible par les humains
- Compatible avec tous les langages
- Facile √† d√©bugger
- Kafka supporte d'autres formats (Avro, Protobuf) mais JSON est plus simple

---

## Points Importants

### 1. **S√©paration des Responsabilit√©s**

Chaque composant a **une seule responsabilit√©** :
- `TrafficProducer` ‚Üí G√©n√©ration
- `DataPreprocessor` ‚Üí Validation
- `ThreatDetector` ‚Üí D√©tection
- `AlertMonitor` ‚Üí Affichage

**Avantage** : Facile √† modifier, tester, d√©bugger

### 2. **D√©couplage via Kafka**

Les composants ne se connaissent pas :
```
Producer ‚Üí Kafka ‚Üê Consumer
    ‚Üì               ‚Üë
Pas de lien direct !
```

**Avantage** :
- Peut ajouter/retirer des consumers sans modifier le producer
- Peut scaler ind√©pendamment (ex: 3 ThreatDetector en parall√®le)
- Peut remplacer un composant sans casser le syst√®me

### 3. **Flux Asynchrone**

```
Producer envoie un message
    ‚Üì
Message dans Kafka (buffer)
    ‚Üì
Consumer lit quand il est pr√™t
```

**Avantage** :
- Producer ne bloque pas en attendant le consumer
- Consumer peut traiter √† son rythme
- Kafka g√®re la file d'attente

### 4. **Gestion d'Erreurs**

```python
try:
    for message in consumer:
        process(message)
except KeyboardInterrupt:
    print("Arr√™t demand√©")
except Exception as e:
    print(f"Erreur: {e}")
finally:
    consumer.close()
    producer.close()
```

**Important** :
- Toujours fermer les connexions Kafka
- G√©rer `KeyboardInterrupt` pour arr√™t propre
- Logger les erreurs pour debugging

### 5. **Configuration Kafka**

```python
# Timeouts importants
request_timeout_ms=30000,  # 30 secondes
max_block_ms=30000,        # 30 secondes
session_timeout_ms=30000   # 30 secondes
```

**Pourquoi** :
- √âvite les timeouts pr√©matur√©s
- Laisse le temps √† Kafka de d√©marrer
- G√®re la latence r√©seau

### 6. **Consumer Groups**

```python
KafkaConsumer(
    'topic',
    group_id='unique-group-id'  # IMPORTANT !
)
```

**R√®gle** : Chaque consumer doit avoir un `group_id` **diff√©rent** pour lire tous les messages

**Exemple** :
```
DataPreprocessor:  group_id='preprocessor-group'
ThreatDetector:    group_id='detector-group'
AlertMonitor:      group_id='monitor-group'
```

Si m√™me `group_id` ‚Üí load balancing (partage des messages)

---

## R√©sum√© pour D√©butants

### Comment lire le code

1. **Commencez par `run_pipeline()`** :
   - C'est le point d'entr√©e
   - Montre l'ordre de d√©marrage

2. **Lisez chaque classe dans l'ordre** :
   - `TrafficProducer` ‚Üí g√©n√®re
   - `DataPreprocessor` ‚Üí valide
   - `ThreatDetector` ‚Üí d√©tecte
   - `AlertMonitor` ‚Üí affiche

3. **Pour chaque classe, suivez ce pattern** :
   ```
   __init__  ‚Üí Initialisation (Kafka clients)
   run()     ‚Üí Boucle principale
   process() ‚Üí Logique m√©tier
   ```

### Concepts cl√©s √† retenir

1. **Kafka = File d'attente distribu√©e**
   - Producer envoie
   - Topic stocke
   - Consumer lit

2. **Threading = Parall√©lisme**
   - Plusieurs t√¢ches en m√™me temps
   - Chaque consumer dans son thread

3. **JSON = Format de donn√©es**
   - dict Python ‚Üî JSON ‚Üî bytes

4. **Pattern Producer-Consumer**
   - Lit depuis topic A
   - Traite
   - √âcrit vers topic B

### Pour d√©bugger

```python
# Ajouter des prints
print(f"[DEBUG] Message re√ßu: {message.value}")

# V√©rifier les topics Kafka
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Lire un topic manuellement
docker exec -it kafka kafka-console-consumer \
  --topic ids-alerts \
  --bootstrap-server localhost:9092 \
  --from-beginning
```

---

## Ressources Suppl√©mentaires

- **Kafka Documentation** : https://kafka.apache.org/documentation/
- **Threading Python** : https://docs.python.org/3/library/threading.html
- **Pattern Producer-Consumer** : https://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem

**Bon apprentissage !**