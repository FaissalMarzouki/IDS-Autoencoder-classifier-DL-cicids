"""
Service principal LLM - Orchestration du traitement des alertes
"""
import json
import logging
import time
from datetime import datetime
from typing import Dict, Any
import sys
import os

# Ajouter le rÃ©pertoire parent au path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from llm_service.alert_consumer import AlertConsumer
from llm_service.explanation_producer import ExplanationProducer
from llm_service.llm_client import LLMClient

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LLMService:
    """Service principal - Consomme alertes, gÃ©nÃ¨re explications, publie"""
    
    def __init__(self):
        self.consumer = AlertConsumer()
        self.producer = ExplanationProducer()
        self.llm_client = LLMClient()
        
        # Statistiques
        self.stats = {
            'processed': 0,
            'errors': 0,
            'start_time': datetime.now()
        }
        
        logger.info("ğŸš€ LLM Service initialisÃ©")
    
    def build_prompt(self, alert: Dict[str, Any]) -> str:
        """
        Construit le prompt LLM Ã  partir de l'alerte
        Utilise le format de FlowPrediction.to_llm_prompt() du notebook
        
        Args:
            alert: Alerte IDS
            
        Returns:
            Prompt structurÃ© en franÃ§ais
        """
        is_attack = alert.get('is_attack', False)
        confidence = alert.get('confidence', 0.0)
        
        severity = "ğŸ”´ CRITIQUE" if is_attack and confidence > 0.9 else \
                   "ğŸŸ  Ã‰LEVÃ‰" if is_attack else \
                   "ğŸŸ¢ NORMAL"
        
        prompt = f"""
## ğŸ” Rapport d'Analyse de Flux RÃ©seau

### Identification
- **Flow ID**: {alert.get('flow_id', 'unknown')}
- **Timestamp**: {alert.get('timestamp', 'N/A')}

### Verdict
- **Classification**: {alert.get('predicted_class', 'Unknown')}
- **Confiance**: {confidence:.2%}
- **SÃ©vÃ©ritÃ©**: {severity}
- **Est une attaque**: {'OUI âš ï¸' if is_attack else 'NON âœ…'}

### Scores d'Anomalie
- **Anomaly Score**: {alert.get('anomaly_score', 0.0):.4f}
- **Reconstruction Error**: {alert.get('reconstruction_error', 0.0):.6f}
- **Comportement anormal dÃ©tectÃ©**: {'OUI' if alert.get('is_anomaly', False) else 'NON'}

### Top Features Contributives
"""
        
        # Ajouter les top features de maniÃ¨re lisible (fallbacks si infos manquantes)
        top_features = alert.get('top_features', []) or []
        if top_features:
            for idx, feature in enumerate(top_features, 1):
                # Supporte les deux clÃ©s ('feature' pour dashboard, 'name' pour LLM)
                name = feature.get('name') or feature.get('feature') or f"Feature_{idx}"
                value = feature.get('value', 0.0)
                importance = feature.get('importance', feature.get('error', 0.0))
                prompt += f"\n- **{name}**: {value:.4f} (importance: {importance:.2%})"
        else:
            prompt += "\n- Non disponible"
        
        prompt += f"""

### ProbabilitÃ©s par Type de Trafic
{json.dumps(alert.get('class_probabilities', {}), indent=2, ensure_ascii=False)}


**Instructions pour l'analyse LLM:**
1. Analyser la classification et la confiance
2. Ã‰valuer le score d'anomalie par rapport au seuil
3. Identifier les features qui ont contribuÃ© Ã  cette classification
4. Expliquer briÃ¨vement l'influence de chaque feature listÃ©e ci-dessus dans la section **Analyse** (pas dans Recommandations)
5. Fournir dans **Recommandations** uniquement des actions concrÃ¨tes pour l'Ã©quipe SOC (pas de description de features)
6. Attribuer un niveau de prioritÃ© (P1/P2/P3/P4)

**TÃ¢che**: Analyse ce flux rÃ©seau et fournir:
1. **SynthÃ¨se**: 1-2 phrases rÃ©sumant l'alerte
2. **Analyse**: Explication technique dÃ©taillÃ©e du type d'attaque
3. **Impact**: Implications pour la sÃ©curitÃ© rÃ©seau
4. **Recommandations**: Actions Ã  prendre (avec bullet points, sans rÃ©-expliquer les features)
5. **PrioritÃ©**: CRITIQUE / Ã‰LEVÃ‰ / MOYEN / BAS

RÃ©ponds en franÃ§ais.
"""
        return prompt
    
    def determine_alert_level(self, alert: Dict[str, Any]) -> str:
        """DÃ©termine le niveau d'alerte basÃ© sur la confiance et la classe"""
        is_attack = alert.get('is_attack', False)
        confidence = alert.get('confidence', 0.0)
        predicted_class = alert.get('predicted_class', '')
        
        if not is_attack:
            return "INFO"
        
        # DDoS/DoS avec haute confiance = CRITICAL
        if confidence >= 0.95 and predicted_class in ['DDoS', 'DoS']:
            return "CRITICAL"
        
        if confidence >= 0.85:
            return "HIGH"
        
        if confidence >= 0.70:
            return "MEDIUM"
        
        if confidence >= 0.50:
            return "LOW"
        
        return "INFO"
    
    def process_alert(self, alert: Dict[str, Any]) -> None:
        """
        Traite une alerte: gÃ©nÃ¨re prompt, appelle LLM, publie explication
        
        Args:
            alert: Alerte IDS depuis Kafka
        """
        flow_id = alert.get('flow_id', 'unknown')
        
        try:
            start_time = time.time()
            
            # 1. Construire le prompt
            prompt = self.build_prompt(alert)
            
            # 2. Appeler le LLM
            logger.info(f"ğŸ¤– GÃ©nÃ©ration explication LLM pour {flow_id}...")
            explanation_content = self.llm_client.generate_explanation(prompt)
            
            # ğŸ”§ DEBUG: Afficher la rÃ©ponse pour la premiÃ¨re alerte
            if self.stats['processed'] == 0:
                logger.info("\n" + "="*80)
                logger.info(f"ğŸ› DEBUG - RÃ©ponse LLM pour la premiÃ¨re alerte ({flow_id}):")
                logger.info("="*80)
                logger.info(f"RÃ©ponse brute:\n{explanation_content}")
                logger.info("="*80 + "\n")
            
            # 3. DÃ©terminer le niveau d'alerte
            alert_level = self.determine_alert_level(alert)
            
            # 4. Construire l'explication complÃ¨te
            processing_time = (time.time() - start_time) * 1000  # en ms
            
            explanation = {
                "alert_id": flow_id,
                "timestamp": datetime.now().isoformat(),
                "explanation": explanation_content,
                "alert_level": alert_level,
                "llm_model": self.llm_client.model,
                "processing_time_ms": round(processing_time, 2)
            }
            
            # 5. Publier dans Kafka
            self.producer.send_explanation(explanation)
            
            # Stats
            self.stats['processed'] += 1
            
            logger.info(
                f"âœ… Alerte traitÃ©e | Flow: {flow_id} | "
                f"Niveau: {alert_level} | "
                f"Temps: {processing_time:.0f}ms | "
                f"Total: {self.stats['processed']}"
            )
            
        except Exception as e:
            self.stats['errors'] += 1
            logger.error(f"âŒ Erreur traitement {flow_id}: {e}")
    
    def run(self) -> None:
        """Boucle principale du service"""
        logger.info("=" * 80)
        logger.info("ğŸ¯ LLM Service dÃ©marrÃ© - En attente d'alertes...")
        logger.info("=" * 80)
        
        try:
            for alert in self.consumer.consume():
                self.process_alert(alert)
                
                # Afficher stats toutes les 10 alertes
                if self.stats['processed'] % 10 == 0:
                    self.print_stats()
                    
        except KeyboardInterrupt:
            logger.info("\nâš ï¸ Interruption utilisateur")
        except Exception as e:
            logger.error(f"âŒ Erreur fatale: {e}")
        finally:
            self.shutdown()
    
    def print_stats(self) -> None:
        """Affiche les statistiques du service"""
        elapsed = (datetime.now() - self.stats['start_time']).total_seconds()
        rate = self.stats['processed'] / elapsed if elapsed > 0 else 0
        
        logger.info("=" * 80)
        logger.info("ğŸ“Š STATISTIQUES")
        logger.info(f"   â€¢ Alertes traitÃ©es: {self.stats['processed']}")
        logger.info(f"   â€¢ Erreurs: {self.stats['errors']}")
        logger.info(f"   â€¢ DÃ©bit: {rate:.2f} alertes/sec")
        logger.info(f"   â€¢ Uptime: {elapsed:.0f}s")
        logger.info("=" * 80)
    
    def shutdown(self) -> None:
        """ArrÃªt propre du service"""
        logger.info("\nğŸ›‘ ArrÃªt du service...")
        
        self.print_stats()
        
        self.consumer.close()
        self.producer.close()
        
        logger.info("ğŸ‘‹ Service arrÃªtÃ© proprement")


def main():
    """Point d'entrÃ©e principal"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘          ğŸ›¡ï¸  LLM SERVICE - IDS ALERT INTERPRETER  ğŸ›¡ï¸          â•‘
â•‘                                                              â•‘
â•‘  Consomme:  ids-alerts (Kafka)                              â•‘
â•‘  GÃ©nÃ¨re:    Explications LLM                                â•‘
â•‘  Publie:    ids-explanations (Kafka)                        â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    service = LLMService()
    service.run()


if __name__ == "__main__":
    main()
